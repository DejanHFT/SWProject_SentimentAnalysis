Title,Author,URL,Number of Comments,Upvotes,Text Content
"How are putative ""mental modules"" put forward by evolutionary psychologists specified at the neural or genetic level?",emporsteigend,https://www.reddit.com/r/askscience/comments/m6atb/how_are_putative_mental_modules_put_forward_by/,16,7,"Evolutionary psychologists tend to make the claim that the mind has many domain-specific ""modules"", each with substantial innate (genetic) specification and each tailored for a putative challenge of the ""environment of evolutionary adaptatedness"".

I have a hard time believing this for a number of reasons.

The first has to do with neural development in humans. The human brain, for the most part, and especially the neocortex, where many of these supposed modules would exist, develops in the fetus according to a fairly coarse mechanism of reaction-diffusion. This in contrast to the mosaic development of a nervous system like that of *C. elegans*, which is specified in neat detail by the organism's genome. So, already, there's a developmental issue with specifying modules: the mechanisms of human brain development are by and large too ""fuzzy"" for exquisite specification of cortical microcircuitry.

The second has to do with the organization of the brain in the adult. If processing is neatly divided into discrete modules, why is there so much recurrence in the brain? Why for example should V1 in the visual cortex *backproject* massively into the LGN? That kind of connectivity certainly is not suggestive of modularity and yet the adult brain is full of it.

My third objection is not biological but computational. As a [PLoS Biology article](http://http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001109) points out:

>A large part of EP's emphasis on massive modularity drew from artificial intelligence (AI) research. While the great lesson from AI research of the 1970s was that domain specificity was critical to intelligent behaviour, the lesson of the new millennium is that intelligent agents (such as driverless robotic cars) require integration and decision-making across domains, regularly utilize general-process tools such as Bayesian analysis, stochastic modelling, and optimization, and are responsive to a variety of environmental cues [73]. However, while AI research has shifted away from an emphasis on domain specificity, some evolutionary psychologists continue to argue that selection would have favoured predominantly domain-specific mechanisms (e.g., [74]). In contrast, others have started to present the case for domain-general evolved psychological mechanisms (e.g., [75],[76]), and evidence from developmental psychology suggests that domain-general learning mechanisms frequently build on knowledge acquired through domain-specific perceptual processes and core cognition [44]. Both domain-specific and domain-general mechanisms are compatible with evolutionary theory, and their relative importance in human information processing will only be revealed through careful experimentation, leading to a greater understanding of how the brain works [44].

When I see someone posit an innately-specified module for detecting dangerous animals like spiders or snakes (most spiders and snakes are harmless but I'll that slide for now), or a module that recognizes signs of high status, I immediately wonder, how is genetic encoding of such things computationally feasible? I am not aware of any artificial intelligence that could successfully recognize shapes (for example of spiders and snakes) under varying angles and lighting conditions in real time, much less something as nebulous as *social status*, that was all hard-coded. Such a project would be nigh on impossible, as I'm sure all but dyed-in-the-wool logicists in AI would tell you. Instead, all such successful projects have used machine *learning* algorithms with broadly domain-general mechanisms. And the data processed and acquired by these algorithms are massive. I would imagine that encoding even one innate mental module in the genome, even barring the biological constraints I just mentioned, would quickly leave little room to encode anything else, and evolutionary psychologists want us to believe there are hundreds if not thousands of these modules!

So, all told, my question is, how does modularity work as described by EP under these formidable biological and computational challenges?"
